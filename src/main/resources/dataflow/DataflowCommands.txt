mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.MinimalisticJob

ERROR: (gcloud.dataflow.jobs.run) PERMISSION_DENIED: (90c46f7df0de2db8): Permission 'resourcemanager.projects.get' denied on project: 'poised-shuttle-384406'

gcloud dataflow jobs run JOB_NAME_TEST --project poised-shuttle-384406 --gcs-location gs://gcpsampleall/dataflow_common/all_jars/gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar

java -cp gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar dataflowwithjava.dataflow.MinimalisticJob --runner=DataflowRunner --project=project poised-shuttle-384406 --gcpTempLocation=gs:gcpsampleall/dataflow_common/temp
--inputFile=gs://YOUR_BUCKET/input/inputFile.txt \
--output=gs://YOUR_BUCKET/output/outputFile.txt

java -jar gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar --runner=DataflowRunner --project=poised-shuttle-384406 --gcpTempLocation=gs://gcpsampleall/dataflow_common/temp --region=us-central1


mvn clean install
gcloud dataflow jobs run BQReadDataflow \
--gcs-location=gs://sample_bucket_all/dataflow/dataflow_jars/gcp_e2e_sample-1.0-SNAPSHOT.jar \
--region=us-central1 \
--parameters="runner=DataflowRunner,mainClass=gcpsample.dataflow.BQReadDataflow" \
--project=poised-shuttle-384406


gcloud dataflow jobs run BQReadDataflow \
--region=us-central1 \
--gcs-location=gs://dataflow_temp6876 \
--project=poised-shuttle-384406 \
--worker-machine-type=n1-standard-1 \
--max-workers=2 \
--jar=gs://sample_bucket_all/dataflow/dataflow_jars/gcp_e2e_sample-1.0-SNAPSHOT.jar \
--class=gcpsample.dataflow.BQReadDataflow

 mvn compile exec:java \
      -Pdataflow-runner compile exec:java \
      -Dexec.mainClass=gcpsample.dataflow.BQReadDataflow \
      -Dexec.args="--project=poised-shuttle-384406 \
      --stagingLocation=gs://sample_bucket_all/dataflow/dataflow_jars \
      --output=gs://dataflow_temp6876/output \
      --runner=DataflowRunner \
      --region=us-central1 \
      --gcpTempLocation=gs://dataflow_temp6876/temp"

gsutil cp gcp-samples-1.0-SNAPSHOT.jar gs://gcpsampleall/dataflow_common/all_jars
gsutil ls gs://gcpsampleall/dataflow_common/all_jars

gsutil cp gcpsamples-1.0-SNAPSHOT.jar gs://gcpsampleall/dataflow_common/all_jars

mvn compile exec:java -Dexec.mainClass=gcpsample.dataflow.BQReadDataflow -Dexec.args="--project=sanguine-anthem-393416 ^
      --stagingLocation=gs://gcpsampleall/dataflow_common/staging --output=gs://gcpsampleall/dataflow_common/output --runner=DataflowRunner --region=us-central1       --gcpTempLocation=gs://gs://gcpsampleall/dataflow_common/temp"

mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.MinimalisticJob -Dexec.args="--runner=DataflowRunner --project=sanguine-anthem-393416  --gcpTempLocation=gs://gcpsampleall/dataflow_common/staging --region=us-central1"

java -jar  gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar  --project=sanguine-anthem-393416 --stagingLocation=gs://gcpsampleall/dataflow_common/staging --gcpTempLocation=gs://gcpsampleall/dataflow_common/temp --runner=DataflowRunner --jobName=my-custom-job --region=us-central1

java -jar  gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar  --project=sanguine-anthem-393416 --stagingLocation=gs://gcpsampleall/dataflow_common/staging --gcpTempLocation=gs://gcpsampleall/dataflow_common/temp --runner=DataflowRunner --jobName=my-custom-job --region=us-central1
gcloud dataflow jobs run my-job-name --gcs-location=gs://gcpsampleall/gcp_java/gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar --region=us-central1 --parameters project=sanguine-anthem-393416,stagingLocation=ggs://gcpsampleall/dataflow_common/staging/,gcpTempLocation=gs://gcpsampleall/dataflow_common/temp,runner=DataflowRunner

java -jar  gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar --Dexec.mainClass=dataflowwithjava.dataflow.BQRead  --project=sanguine-anthem-393416 --stagingLocation=gs://gcpsampleall/dataflow_common/staging --gcpTempLocation=gs://gcpsampleall/dataflow_common/temp --runner=DataflowRunner --jobName=my-custom-job --region=us-central1
gcloud dataflow jobs run bqdataread  --gcs-location=gs://gcpsampleall/gcp_java/gcp-dataflow-withjava-1.0-SNAPSHOT-bundled.jar --region=us-central1 --parameters project=sanguine-anthem-393416,stagingLocation=ggs://gcpsampleall/dataflow_common/staging/,gcpTempLocation=gs://gcpsampleall/dataflow_common/temp,runner=DataflowRunner

mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.BQRead -Dexec.args="--runner=DataflowRunner --project=sanguine-anthem-393416  --gcpTempLocation=gs://gcpsampleall/dataflow_common/staging --region=us-central1"

mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.HelloWorld -Dexec.args="--runner=DataflowRunner --project=healthy-reason-396205 \
                 --stagingLocation=gs://dataflow-base-bucket/staging/ \
                 --templateLocation=gs://dataflow-base-bucket/templates/helloworld-template \
                 --region=us-east1"

mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.HelloWorld -Dexec.args="--runner=DataflowRunner --project=healthy-reason-396205 --templateLocation=gs://dataflow-base-bucket/templates/helloworld-template --region=us-east1"
mvn compile exec:java -Dexec.mainClass=dataflowwithjava.dataflow.HelloWorld -Dexec.args="--runner=DataflowRunner --project=healthy-reason-396205 --templateLocation=gs://dataflow-base-bucket/templates/helloworld-template --region=us-east1"
mvn compile exec:java \
-Dexec.mainClass=org.apache.beam.examples.FileTranslatePipeline \
-Dexec.args="--runner=DataflowRunner \
--project=mtech-infosec-tokenize-poc \
--stagingLocation=gs://btl-dataflow-job/staging \
--templateLocation=gs://btl-dataflow-job/templates/btl-file-translate-pipeline-template \
--region=us-central1 \
--network=mtech-infosec-tokenize-vpc \
--subnetwork=https://www.googleapis.com/compute/v1/projects/mtech-infosec-tokenize-poc/regions/us-central1/subnetworks/subnet-central1 \
--inputFile=gs://btl-dataflow-job/TESTFILE.FROM.CITI.2M.txt \
--output=gs://btl-dataflow-job/NEW_OUTPUT_3W_GCPTESTFILEFROMCITI \
--numWorkers=3 \
--serviceAccount=dataflow-default@mtech-infosec-tokenize-poc.iam.gserviceaccount.com"

java -cp ./target/beamwordcount-bundled-VER-1.0.jar beamwordcount.WordCount  --inputFile=gs://dataflow-base-bucket/input/pom.xml --outputFile=gs://dataflow-base-bucket/output --runner=dataflow --project=healthy-reason-396205 --stagingLocation=gs://dataflow-base-bucket/staging/ --gcpTempLocation=gs://dataflow-base-bucket/temp --region=us-east1

mvn clean package -P dataflow
mvn exec:java -Dexec.mainClass="beamwordcount.WordCount"  -Dexec.args="--region=us-east1 --project=healthy-reason-396205 --inputFile=gs://dataflow-base-bucket/input/pom.xml --outputFile=gs://dataflow-base-bucket/output --runner=dataflow  --stagingLocation=gs://dataflow-base-bucket/staging/ --gcpTempLocation=gs://dataflow-base-bucket/temp "
java -cp ./target/beamwordcount-bundled-VER-1.0.jar beamwordcount.WordCount --inputFile=test.txt


mvn compile exec:java \
-P dataflow \
-Dexec.cleanupDaemonThreads=false \
-Dexec.mainClass=beamwordcount.WordCount \
-Dexec.args="--runner=DataflowRunner \
--project=healthy-reason-396205 \
--inputFile=gs://dataflow-base-bucket/input/pom.xml \
--outputFile=gs://dataflow-base-bucket/output \
--stagingLocation=gs://dataflow-base-bucket/staging \
--gcpTempLocation=gs://dataflow-base-bucket/temp \
--region=us-east1"

mvn compile exec:java \
-P dataflow \
-Dexec.cleanupDaemonThreads=false \
-Dexec.mainClass=beamwordcount.WordCount \
-Dexec.args="--runner=DataflowRunner \
--project=healthy-reason-396205 \
--inputFile=gs://dataflow-base-bucket/input/pom.xml \
--outputFile=gs://dataflow-base-bucket/output \
--stagingLocation=gs://dataflow-base-bucket/staging \
--gcpTempLocation=gs://dataflow-base-bucket/temp \
--templateLocation=gs://dataflow-base-bucket/templates/dftemplate.json \
--region=us-east1"

gcloud dataflow jobs run template-dataflow --project=healthy-reason-396205 --gcs-location gs://dataflow-base-bucket/templates/dftemplate.json --region us-east1 --max-workers 1 --worker-machine-type n1-standard-1 --staging-location gs://dataflow-base-bucket/staging --disable-public-ips





# Create the bucket
gsutil mb gs://your-bucket-name/

# Create necessary locations
gsutil cp /dev/null gs://dataflow-base-bucket/staging/
gsutil cp /dev/null gs://dataflow-base-bucket/templates/

gcloud dataflow jobs run helloworld-job \
    --gcs-location=gs://dataflow-base-bucket/templates/helloworld-template \
    --region=us-east1


